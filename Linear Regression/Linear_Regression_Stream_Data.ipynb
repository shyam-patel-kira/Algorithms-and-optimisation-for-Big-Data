{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Multi Variate Linear Regression using Gradient Descent for stream data*** <br />\n",
    "***Sliding Window Approach***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Procedure for Online Regression using Sliding Window Approach***\n",
    "\n",
    "1. The Batch Data Arrives (here from a file)\n",
    "2. Initially for the first step, we choose some random values of weights (thetas)\n",
    "3. We apply gradient descent on that batch and get the updated parameters\n",
    "4. We pass those parameters to the next batch\n",
    "5. We apply the same method for this batch too, just the weights are not chosen ramdomly\n",
    "6. We repeat the same for all other batched.\n",
    "7. The weights we get after the last batch are the final set of weights\n",
    "\n",
    "***Comparision with other approaches***\n",
    "***Advantages***\n",
    "1. We do not need to store the batch data.\n",
    "2. Lower iterations for batches.\n",
    "\n",
    "***Disadvantages***\n",
    "1. As the new data arrives, the previous records are discarded.\n",
    "2. We can't have global view of all the records.\n",
    "3. Hence, we can't accurately model the entire stream data.\n",
    "\n",
    "***We have implemented for Multiple Variate Dataset. Same procedure can be applied for Uni Variate Too***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.datasets import load_boston\n",
    "from numpy.linalg import inv, pinv, LinAlgError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x_train: <class 'numpy.ndarray'> Shape of x_train: (404, 14)\n",
      "Type of x_test: <class 'numpy.ndarray'> Shape of x_test: (102, 14)\n"
     ]
    }
   ],
   "source": [
    "#Loading Dataset\n",
    "X,Y = load_boston(True)\n",
    "\n",
    "#Adding dummy column to X\n",
    "X_new=np.ones((X.shape[0],X.shape[1]+1))\n",
    "X_new[:,1:]=X\n",
    "X=X_new\n",
    "\n",
    "# Splitting the dataset into training set and testing set\n",
    "# 80% Training and 20 % Testing \n",
    "index = int(0.8 * len(X))\n",
    "x_train,x_test=X[:index],X[index:]\n",
    "y_train,y_test=Y[:index],Y[index:]\n",
    "\n",
    "# display the shape/dimensions for X_train and X_test\n",
    "print(\"Type of x_train:\", type(x_train), \"Shape of x_train:\", x_train.shape)\n",
    "print(\"Type of x_test:\", type(x_test), \"Shape of x_test:\", x_test.shape)\n",
    "\n",
    "# Normalizing the Data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler=StandardScaler()\n",
    "# scaler.fit(x_train[:,1:])\n",
    "# x_train[:,1:]=scaler.transform(x_train[:,1:])\n",
    "# x_test[:,1:]=scaler.transform(x_test[:,1:])\n",
    "\n",
    "#Rearranging Y and storing X,Y in csv format\n",
    "Y=np.reshape(Y,newshape=(Y.shape[0],1))\n",
    "boston=np.hstack((X,Y)) #Combining the X and Y and making in horizontal stack form\n",
    "boston=pd.DataFrame(boston) #Converting to pandas Dataframe\n",
    "boston.to_csv('boston.csv', header='None', index=False)  #Converting to CSV Format and writing in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generation of Stream\n",
    "\n",
    "def stream_data(wsize=100):\n",
    "    counter=0   #Initializing\n",
    "    for chunk in pd.read_csv('boston.csv', header=None, chunksize=wsize): # Opening file and reading data into chunks\n",
    "        chunk_array=chunk.values    #Converting pandas dataframe to numpy arrays\n",
    "        counter=counter+1   #incrementing the counter\n",
    "        yield (chunk_array[:,:-1], chunk_array[:,-1])   # Streams the chunk data without exiting/returning the function\n",
    "        if counter >= 4:  #Checking the counter until it comes at the end of data that needs to stream\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost Function\n",
    "def cost_function(X, y, theta):\n",
    "    m = y.size\n",
    "    error = np.dot(X, theta.T) - y\n",
    "    cost = 1/(2*m) * np.dot(error.T, error)\n",
    "    return cost, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent\n",
    "def gradient_descent(X, y, theta, alpha, iters):\n",
    "    cost_array = np.zeros(iters)\n",
    "    m = y.size\n",
    "    for i in range(iters):\n",
    "        cost, error = cost_function(X, y, theta)\n",
    "        theta = theta - (alpha * (1/m) * np.dot(X.T, error))\n",
    "        cost_array[i] = cost\n",
    "    return theta, cost_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** BATCH 1*****\n",
      "Cost Before Gradient Descent is: 261.70925\n",
      "Cost After  Gradient Descent is: 203.12089236005522\n",
      "Mean Absolute Error:  13.750193611001542\n",
      "Mean Squared  Error:  214.11059344073243\n",
      "\n",
      "***** BATCH 2*****\n",
      "Cost Before Gradient Descent is: 274.05601926130316\n",
      "Cost After  Gradient Descent is: 221.36775788033458\n",
      "Mean Absolute Error:  11.427417916394079\n",
      "Mean Squared  Error:  154.5405496562384\n",
      "\n",
      "***** BATCH 3*****\n",
      "Cost Before Gradient Descent is: 341.1365430832656\n",
      "Cost After  Gradient Descent is: 269.2976460320818\n",
      "Mean Absolute Error:  9.02041989864586\n",
      "Mean Squared  Error:  102.72275428949952\n",
      "\n",
      "***** BATCH 4*****\n",
      "Cost Before Gradient Descent is: 130.58639410915137\n",
      "Cost After  Gradient Descent is: 113.96605605838378\n",
      "Mean Absolute Error:  7.780349840087024\n",
      "Mean Squared  Error:  80.4851164359746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Getting stream Data\n",
    "sdata = stream_data(100)   # <-- Yeilds 100 data points/instances at a time\n",
    "\n",
    "# Deciding the Learning Rate and Number of Iterations for each batch\n",
    "iterations = 10\n",
    "alpha = 0.001\n",
    "cnt = 0\n",
    "\n",
    "for (x,y) in sdata:\n",
    "    \n",
    "    # Normalize our features\n",
    "    X = (x - x.mean()) / x.std()\n",
    "\n",
    "    if cnt==0:     # <-- Initialize Theta Values to 0    \n",
    "        theta = np.zeros(X.shape[1])\n",
    "        cnt = cnt+1\n",
    "    \n",
    "    initial_cost, error_mat = cost_function(X, y, theta)\n",
    "    print(\"***** BATCH {0}*****\".format(cnt))\n",
    "    print('Cost Before Gradient Descent is: {0}'.format(initial_cost))\n",
    "    # Run Gradient Descent [Theta gets updates and gets passed to new batch]\n",
    "    theta, cost_num = gradient_descent(X, y, theta, alpha, iterations)\n",
    "    final_cost, error_mat = cost_function(X, y, theta)\n",
    "    print(\"Cost After  Gradient Descent is: {0}\".format(final_cost))\n",
    "    \n",
    "    # Calculating Statistics in the Trained Model for this batch\n",
    "    x_test_std = (x_test - x_test.mean()) / x_test.std()\n",
    "    y_pred = np.dot(theta, x_test_std.T)\n",
    "    print(\"Mean Absolute Error: \", metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print(\"Mean Squared  Error: \", metrics.mean_squared_error(y_test, y_pred))\n",
    "    print()\n",
    "    cnt = cnt + 1\n",
    "\n",
    "\n",
    "# Display cost chart\n",
    "# plotChart(iterations, cost_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
